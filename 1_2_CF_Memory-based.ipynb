{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colaborative Filtering (CF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory-Based\n",
    "Utiliza algun tipo de métrica para medir similitud entre Usuarios o Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas (Similitudes/Distancias):\n",
    "#### Similitud de pearson (coeficiente de correlacion)\n",
    "\n",
    "Se toman todos los items que los usuarios u y a calificaron y se evalúa que tan parecido lo hicieron\n",
    "\n",
    "$\\huge w_{a,u} = \\frac{\\sum_{i=1}^n{(r_{a,i} - \\bar{r_a})(r_{u,i} - \\bar{r_u})}}{n\\sigma_a \\sigma_u} = \\frac{\\sum_{i=1}^n{(r_{a,i} - \\bar{r_a})(r_{u,i} - \\bar{r_u})}}{{\\sqrt{\\sum_{i=1}^n{(r_{a,i} - \\bar{r_a})^2}} \\sqrt{\\sum_{i=1}^n(r_{u,i} - \\bar{r_u})^2}}}$\n",
    "\n",
    "- $w_{a,u}$ similitud o correlacion de pearson entre usuario a y u\n",
    "- $\\sigma_a$ y $\\sigma_u$ son los desvios de $a$ y $u$ respectivamente\n",
    "- $n$ son todos los items que el usuario $u$ y $a$ calificaron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Se podria medir similitud entre items de la misma forma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similitud del coseno\n",
    "Suponiendo que las medias $\\bar{r_u}$ y $\\bar{r_a}$ son cero nos queda la similitud del coseno:\n",
    "\n",
    "$\\huge w_{a,u} = \\frac{\\sum_{i=1}^n{r_{a,i}r_{u,i}}}{{\\sqrt{\\sum_{i=1}^n{r_{a,i}^2}} \\sqrt{\\sum_{i=1}^n r_{u,i}^2}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similitud de Jaccard\n",
    "Se usa en situaciones binarias (Like / dislike)\n",
    "\n",
    "$\\huge J(u_1, u_2) = \\frac {\\| L_{u_1} \\cap L_{u_2} \\| + \\| D_{u_1} \\cap D_{u_2} \\| - \\| L_{u_1} \\cap D_{u_2} \\| - \\| D_{u_1} \\cap L_{u_2} \\|} {\\|L_{u_1} \\cup D_{u_2} \\cup L_{u_2} \\cup D_{u_1}\\|}$\n",
    "\n",
    "$\\huge w_{a,u} = \\frac{\\sum_{i=1}^n{r_{a,i}r_{u,i}}}{R_a\\cup R_u}$\n",
    "$R_a$ y $R_u$ son la cantidad de items que califico el usuario a y el usuario u respectivamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otras metricas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distancia Euclidiana\n",
    "- Manhattan\n",
    "- Hamming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimación de \"probabilidad\" de que un usuario haya \"likeado/dislikeado\"\n",
    "Esta entre -1 y 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\huge P(u_j, i_k) = \\frac{\\sum_{i=1}^{N_L} J(u_j, u_{i}^k) - \\sum_{i=1}^{N_D} J(u_j, u_{i}^k)}{N_L + N_D}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La posibilidad de que el usuario $u_j$ likee el elemento $i_k$ se define como $P(u_j, i_k)$ donde $N_L$ y $N_D$ son la cantidad de usuarios que likearon y dislikearon el elemento $i_k$ respectivamente. Los $u_i^k$ corresponen a los usuarios que likearon o dislikearon el item $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que las dos sumas barren todos los usuarios.  \n",
    "La primer suma, sumará si hay similitud entre los usuarios que likearon y el usuario en cuestion  \n",
    "La segunda suma, restará si hay similitud entre los usuarios que dislikearon y el usuario en cuestion  \n",
    "Siempre todo analizado sobre el mismo item  \n",
    "Si mi indice de Jaccard con todos los que likearon es 1 y mi indice de Jaccard con todos los que dislikearon es -1 P = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimación de rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\huge \\hat{x}_{k,m} = \\frac{\\bar{x}_k+\\sum_{u_a}sim_u(u_k,u_a)(x_{a,m}-\\bar{x}_{u_a})}{\\sum_{u_a}|sim_u(u_k,u_a)|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\hat{x}_{k,m}$ -> Rating estimado del usuario k'esimo a la pelicula m\n",
    "- $\\bar{x}_k$ -> Promedio de ratings del usuario K'esimo (sobre todas la peliculas que calificó)\n",
    "- $sim_u(u_k,u_a)$ -> Similitud entre usuarios $u_k$ y $u_a$\n",
    "- $x_{a,m}$ -> Rating que dio el usuario a a la pelicula m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy example:\n",
    "Estamos en este ejemplo haciendo la matriz de $n_un_i$, al reves que en CB\n",
    "- 1 -> Likes\n",
    "- -1 -> Dislikes\n",
    "- 0 -> Ni like ni dislike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R = np.array([[ 1, 1, 1, 0, 0, 0],\n",
    "              [ 0, 0, 0, 0, 1, 0],\n",
    "              [ 1, 1, 1,-1,-1,-1],\n",
    "              [-1,-1,-1, 1, 1, 1],\n",
    "              [ 0, 0, 0, 0, 0, 0],\n",
    "              [ 0, 0, 0, 1, 1, 0],\n",
    "              [ 0, 0, 0,-1,-1,-1],\n",
    "              [ 1, 0, 0, 0,-1, 0],\n",
    "              [ 1, 1, 0, 0,-1,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 2.449489742783178 2.0 0.8164965809277261\n"
     ]
    }
   ],
   "source": [
    "index_1 = 2\n",
    "index_2 = 8 #3\n",
    "# Cosine\n",
    "suma_productos = (R[index_1]*R[index_2]).sum()\n",
    "modulo_1 = ((R[index_1]**2).sum())**0.5\n",
    "modulo_2 = ((R[index_2]**2).sum())**0.5\n",
    "metrica = suma_productos/(modulo_1*modulo_2)\n",
    "print(suma_productos, modulo_1, modulo_2, metrica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics.pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similarities = cosine_similarity(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8164965809277261, -1.0000000000000002)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities[2,8], similarities[2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getJaccardSimilarityMatrix(R):\n",
    "    R_abs = 1.0*(abs(R)>0)\n",
    "    intersect = R_abs.dot(R_abs.T)\n",
    "    users_count = R_abs.sum(axis = 1)\n",
    "    users_count = users_count.reshape(users_count.shape[0],1)\n",
    "    denom = users_count + users_count.T\n",
    "    denom = denom - intersect\n",
    "    denom[denom==0] = 1\n",
    "    similarity = np.dot(R,R.T)\n",
    "    similarity = similarity/denom\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jaccard_sim = getJaccardSimilarityMatrix(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6666666666666666, -1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_sim[2,8], jaccard_sim[2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictions(R, similarityMatOrig, divide_by_weights_sum = True, count_diag = False, means = 0):\n",
    "    # divide_by_weights_sum -> Divide por la suma de los pesos y no por la cantidad de elementos likeados/dislikeados\n",
    "    similarityMat = similarityMatOrig.copy()\n",
    "    if not count_diag:\n",
    "        np.fill_diagonal(similarityMat,0)\n",
    "    difMat = (R-means).T.dot(similarityMat).T\n",
    "    if divide_by_weights_sum:\n",
    "        denomin = abs(similarityMat)[:,::-1].sum(axis = 1)\n",
    "    else: \n",
    "        denomin = abs(R.T).sum(axis=1)\n",
    "    denomin[denomin == 0] = 1\n",
    "    nomalizer = abs(R.T).sum(axis=1)\n",
    "    nomalizer[nomalizer == 0] = 1\n",
    "    if divide_by_weights_sum:\n",
    "        result = (difMat.T/denomin).T\n",
    "    else:\n",
    "        result = difMat/denomin\n",
    "    result = result + means\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calculated_prediction = predictions(R, jaccard_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.8484848484848485, 0.5621621621621622, -0.627027027027027)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculated_prediction[0,5], calculated_prediction[8,2], calculated_prediction[8,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación\n",
    "- Medir accuracy en datos de testing\n",
    "- Definiendo un TOP-K, vemos que porcentaje de las veces, algo que se likeo entra dentro de ese top K en mi sistema de recomendación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![comparacion_de_metricas_rec_sys.png](comparacion_de_metricas_rec_sys.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que para el caso de \"Pearson not train\", el 37% de las veces, el item relevante aparece dentro del 2% top list. Es decir, el 37% de las veces el item esta dentro de los primeros 20 items recomendados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![comparacion_de_metricas_rec_sys_2.png](comparacion_de_metricas_rec_sys_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo movielens**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! wget http://files.grouplens.org/datasets/movielens/ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip ml-100k.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BLOG_CCA_8.png](BLOG_CCA_8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cargo dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users = 943 | Number of movies = 1682\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('ml-100k/u.data', sep='\\t', names=header)\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "print('Number of users = ' + str(n_users) + ' | Number of movies = ' + str(n_items))\n",
    "df[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separo test de train y armo matrices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(df, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create two user-item matrices, one for training and another for testing\n",
    "train_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in train_data.itertuples():\n",
    "    train_data_matrix[line[1]-1, line[2]-1] = line[3]\n",
    "\n",
    "test_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in test_data.itertuples():\n",
    "    test_data_matrix[line[1]-1, line[2]-1] = line[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n",
      "(943, 1682)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 3., 0., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_data_matrix.shape)\n",
    "print(train_data_matrix.shape)\n",
    "train_data_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-Item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BLOG_CCA_11.png](BLOG_CCA_11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\huge \\hat{x}_{k,m} = \\frac{\\bar{x}_k+\\sum_{u_a}sim_u(u_k,u_a)(x_{a,m}-\\bar{x}_{u_a})}{\\sum_{u_a}|sum_u(u_k,u_a)|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculo media solo teniendo en cuando los distintos de cero\n",
    "mu = train_data_matrix[train_data_matrix.nonzero()].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.13982086 0.04161716 ... 0.12988924 0.13040404 0.3362147 ]\n",
      " [0.13982086 1.         0.09874805 ... 0.16269861 0.0990332  0.09777028]\n",
      " [0.04161716 0.09874805 1.         ... 0.04993324 0.15207632 0.02103247]\n",
      " ...\n",
      " [0.12988924 0.16269861 0.04993324 ... 1.         0.07174014 0.05891074]\n",
      " [0.13040404 0.0990332  0.15207632 ... 0.07174014 1.         0.11633849]\n",
      " [0.3362147  0.09777028 0.02103247 ... 0.05891074 0.11633849 1.        ]]\n",
      "(943, 943)\n"
     ]
    }
   ],
   "source": [
    "user_similarity = cosine_similarity(train_data_matrix)\n",
    "print(user_similarity)\n",
    "print(user_similarity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 456 822 ... 687 272 240]\n",
      " [  1 700 930 ... 171 669 179]\n",
      " [  2 723 783 ... 589 348 224]\n",
      " ...\n",
      " [940 816 688 ... 146 425 315]\n",
      " [941 779  90 ... 661  33 691]\n",
      " [942 631 681 ... 630 625 588]]\n"
     ]
    }
   ],
   "source": [
    "# Podemos ver con esto que usuarios se parecen más entre si\n",
    "sorted_users = np.argsort(user_similarity, axis = 1).T[::-1].T\n",
    "print(sorted_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El usuario 456 es el mas similar al usuario 0 y tiene una similitud de 0.44309547517490067\n",
      "El usuario 700 es el mas similar al usuario 1 y tiene una similitud de 0.493090272341686\n"
     ]
    }
   ],
   "source": [
    "print('El usuario {} es el mas similar al usuario 0 y tiene una similitud de {}'.format(sorted_users[0, 1], user_similarity[0, sorted_users[0, 1]]))\n",
    "print('El usuario {} es el mas similar al usuario 1 y tiene una similitud de {}'.format(sorted_users[1, 1], user_similarity[1, sorted_users[1, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, type='user'):\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        #You use np.newaxis so that mean_user_rating has same format as ratings\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_prediction = predict(train_data_matrix, user_similarity, type='user')+mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE: 1.3805835622679588\n",
      "User-based CF RMSE: 1.360518049957164\n"
     ]
    }
   ],
   "source": [
    "print('User-based CF RMSE: ' + str(rmse(user_prediction, train_data_matrix)))\n",
    "print('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item-Item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BLOG_CCA_10.png](BLOG_CCA_10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\huge \\hat{x}_{k,m} = \\frac{\\sum_{i_b}sim_i(i_m,i_b)x_{k,b}}{\\sum_{i_b}|sum_i(i_m,i_b)|}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
